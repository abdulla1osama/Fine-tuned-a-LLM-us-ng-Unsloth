# LLM Fine-Tuning with unsloth
This project demonstrates efficient fine-tuning of a LLM:

- Unsloth (fast LoRA/QLoRA fine-tuning)
- Jupyter notebook for experiments

## Features

- Super fast SFT with Unsloth
- Memory-efficient LoRA adapters
- Notebook-based workflow
- GitHub-ready cleaned notebook

## Project Structure

├── LLM_Llama.ipynb # training / experiments notebook
├── README.md
└── data/ # datasets


